{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "15528/15528 [==============================] - 17s - loss: 0.1474 - acc: 0.9444    \n",
      "Epoch 2/2\n",
      "15528/15528 [==============================] - 18s - loss: 0.0711 - acc: 0.9740    \n",
      "Test score: 0.0600529295538\n",
      "Test accuracy: 0.979649665121\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the face landmark dataset.\n",
    "Adapted from Keras MNIST CNN example code.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "nb_landmarks = 5\n",
    "nb_epoch = 2\n",
    "nb_verbose = 1\n",
    "#nb_validation_data = (X_test, _Y_test)\n",
    "nb_validation_data = None\n",
    "\n",
    "# input image dimensions\n",
    "img_chns, img_rows, img_cols = 3, 20, 20\n",
    "# number of convolutional filters to use\n",
    "nb_filters = [32, 64]\n",
    "# size of pooling area for max pooling\n",
    "nb_pool_sizes = [(2, 2), (2, 2)]\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "# activator\n",
    "nb_activator = 'tanh'\n",
    "# number of fully connected neurons in the penultimate layer\n",
    "nb_penu_neurons = 128\n",
    "# size of output vector, four \"corner values\" for each landmark\n",
    "nb_output_size = nb_landmarks * 4\n",
    "\n",
    "input_img = Input(shape=(img_chns, img_rows, img_cols), dtype='float32', name='input_img')\n",
    "\n",
    "x = input_img\n",
    "x = (Convolution2D(nb_filters[0], nb_conv, nb_conv))(x)\n",
    "x = (Activation(nb_activator))(x)\n",
    "x = (MaxPooling2D(pool_size=nb_pool_sizes[0]))(x)\n",
    "x = (Convolution2D(nb_filters[1], nb_conv, nb_conv))(x)\n",
    "x = (Activation(nb_activator))(x)\n",
    "x = (MaxPooling2D(pool_size=nb_pool_sizes[1]))(x)\n",
    "x = (Dropout(0.25))(x)\n",
    "\n",
    "x = (Flatten())(x)\n",
    "x = (Dense(nb_penu_neurons))(x)\n",
    "x = (Activation(nb_activator))(x)\n",
    "x = (Dropout(0.5))(x)\n",
    "#output_landmarks = [Activation('sigmoid')((Dense(4, name='landmark-%d'%(_)))(x)) for _ in range(nb_landmarks)]\n",
    "output = Activation('sigmoid')(Dense(1, name=\"detect_face\")(x))\n",
    "\n",
    "model = Model(input=input_img, output=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #loss_weights=[1, 1, 5, 1, 1],\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=nb_verbose, validation_data=nb_validation_data)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model_filename = '../model/corners-all(ratio-0.8,rand-1337),20px,500ep'\n",
    "print(model.to_json(), file=open(model_filename+'.json', 'w'))\n",
    "model.save_weights(model_filename+'.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 0 0.0 0.000102047997643 True\n",
      "547 1 1.0 0.999546229839 True\n",
      "2214 2 1.0 0.997172415257 True\n",
      "1244 3 1.0 0.999528050423 True\n",
      "2462 4 0.0 0.000159538467415 True\n",
      "3735 5 1.0 0.999836802483 True\n",
      "1472 6 1.0 0.999602735043 True\n",
      "2372 7 0.0 9.17866636883e-05 True\n",
      "1880 8 1.0 0.999778449535 True\n",
      "1066 9 0.0 0.00053214840591 True\n",
      "2987 10 1.0 0.999618172646 True\n",
      "2916 11 1.0 0.99924904108 True\n",
      "49 12 0.0 0.0647002160549 True\n",
      "622 13 0.0 0.00011810286378 True\n",
      "1844 14 1.0 0.997212707996 True\n",
      "3382 15 1.0 0.998977184296 True\n",
      "1084 16 0.0 0.0454299002886 True\n",
      "1140 17 0.0 0.000623564526904 True\n",
      "2861 18 1.0 0.972686827183 True\n",
      "2109 19 0.0 9.64103601291e-05 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\cnn\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:74: UserWarning: Low image dynamic range; displaying image with stretched contrast.\n",
      "  warn(\"Low image dynamic range; displaying image with \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1393 20 0.0 0.000121594042866 True\n",
      "3579 21 1.0 0.999157547951 True\n",
      "2827 22 0.0 0.0003537038574 True\n",
      "1997 23 1.0 0.989103078842 True\n",
      "1547 24 0.0 0.00019816114218 True\n",
      "1767 25 0.0 0.960856497288 False\n",
      "2529 26 0.0 0.000507330638357 True\n",
      "352 27 0.0 0.992663502693 False\n",
      "720 28 1.0 0.999788701534 True\n",
      "1752 29 1.0 0.999783813953 True\n"
     ]
    }
   ],
   "source": [
    "# observe learning results\n",
    "import random\n",
    "y_converter = lambda y : np.array(list(map(corners_to_coord, y)))\n",
    "\n",
    "plt.figure()\n",
    "ind_picked = list(random.sample(range(len(Y_test)), 30))\n",
    "for iplt, i in enumerate(ind_picked) :\n",
    "    plt.subplot(5, 6, iplt+1)\n",
    "    img = X_test[i].transpose((1,2,0))\n",
    "    print(i, iplt, Y_test[i], Y_pred[i][0], int(Y_test[i])==int(Y_pred[i][0]+.5))\n",
    "    io.imshow(img)\n",
    "    '''\n",
    "    pts2 = y_converter(Y_test[i])\n",
    "    plt.plot(pts2[:,0]*img_rows, pts2[:,1]*img_cols, 'o')\n",
    "    pts = y_converter(Y_pred[i])\n",
    "    plt.plot(pts[:,0]*img_rows, pts[:,1]*img_cols, 'ro')\n",
    "    '''\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Y_data_to_model(Y) :\n",
    "    return list(np.transpose(Y, (1,0,2)))\n",
    "def Y_model_to_data(Y) :\n",
    "    return np.transpose(np.array(Y), (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8003, 3, 20, 20)\n",
      "Y shape: (8003, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "from face_data import *\n",
    "_X = X; _Y = Y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15528, 3, 20, 20)\n",
      "Y_train shape: (15528,)\n",
      "15528 train samples\n",
      "3882 test samples\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = split_data(X, Y, ratio_train=0.8, rand_seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# non face data\n",
    "from glob import glob\n",
    "paths = glob('../../../nonface_20/*/*.png')\n",
    "\n",
    "from skimage import data, io, filters\n",
    "import numpy as np\n",
    "X_nonface = np.array([np.transpose(io.imread(f), (2,0,1)) for f in paths if np.amax(io.imread(f)) > 1])\n",
    "X_nonface.astype('float32')\n",
    "X_nonface = X_nonface/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = np.append(np.ones((_X.shape[0], 1)), np.zeros((X_nonface.shape[0], 1)))\n",
    "X = np.append(_X, X_nonface, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[f for f in paths if np.amax(io.imread(f)) <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "np.amax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\cnn\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:74: UserWarning: Low image dynamic range; displaying image with stretched contrast.\n",
      "  warn(\"Low image dynamic range; displaying image with \"\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "io.imshow(X_test[2907].transpose((1,2,0)))\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
